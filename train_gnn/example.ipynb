{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEFoJxhLE3PM",
        "outputId": "f0769394-8e77-4b49-bfe5-7f8a29256d36"
      },
      "source": [
        "!pip install mxnet\n",
        "!pip install dgl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting dgl\n",
            "  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWH3YtM1KxYj"
      },
      "source": [
        "# Need to set the dgl backend\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"mxnet\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bc8pBXpE1wX",
        "outputId": "ee0866e0-6b2b-4ce7-ee97-6a0f0fccdba3"
      },
      "source": [
        "import dgl.data\n",
        "dataset = dgl.data.CoraGraphDataset()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using backend: mxnet\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzzvpxMMUa1k"
      },
      "source": [
        "g = dataset[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5S1weWYoTJ5",
        "outputId": "a0ae08a2-c754-4b84-a287-e490e4656547"
      },
      "source": [
        "print('Node features')\n",
        "print(g.ndata)\n",
        "print('Edge features')\n",
        "print(g.edata)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node features\n",
            "{'train_mask': \n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "<NDArray 2708 @cpu(0)>, 'val_mask': \n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "<NDArray 2708 @cpu(0)>, 'test_mask': \n",
            "[0. 0. 0. ... 1. 1. 1.]\n",
            "<NDArray 2708 @cpu(0)>, 'label': \n",
            "[3 4 4 ... 3 3 3]\n",
            "<NDArray 2708 @cpu(0)>, 'feat': \n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "<NDArray 2708x1433 @cpu(0)>}\n",
            "Edge features\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjbQ9XdVoV7r"
      },
      "source": [
        "from dgl.nn import GraphConv\n",
        "from mxnet import gluon, init, npx, autograd\n",
        "from mxnet.gluon import nn, rnn\n",
        "import mxnet as mx\n",
        "\n",
        "class GCN(nn.Block):\n",
        "    def __init__(self, in_feats, h_feats, num_classes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.activ = nn.Activation(\"relu\")\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "        self.sig = nn.Activation(\"sigmoid\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = self.activ(h)\n",
        "        h = self.conv2(g, h)\n",
        "        #h = self.sig(h)\n",
        "        return h\n",
        "\n",
        "net = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
        "net.initialize(init.Normal(0.01))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fgdyppvRlGp",
        "outputId": "a128c5ee-46cc-4741-b509-92de75123055"
      },
      "source": [
        "dataset.num_classes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t01lGjeZqqVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54764858-68bd-4e01-af8e-d2feb442bb4b"
      },
      "source": [
        "# [TO-DO] training function\n",
        "def train(g, net, n_epochs, train_params):\n",
        "    trainer = gluon.Trainer(net.collect_params(), \"adam\", train_params)\n",
        "    loss_func = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    labels_one_hot = mx.nd.one_hot(labels, 7)\n",
        "    train_mask_bool = list(g.ndata['train_mask'].asnumpy())\n",
        "    valid_mask_bool = list(g.ndata['val_mask'].asnumpy())\n",
        "    test_mask_bool = list(g.ndata['test_mask'].asnumpy())\n",
        "\n",
        "    train_mask = []\n",
        "    valid_mask = []\n",
        "    test_mask = []\n",
        "    for item in [(train_mask_bool, train_mask), (valid_mask_bool, valid_mask), (test_mask_bool, test_mask)]:\n",
        "        for i in range(len(item[0])):\n",
        "            if item[0][i]==1: item[1].append(int(i))\n",
        "\n",
        "    train_mask = mx.ndarray.ndarray.array(train_mask, dtype=\"int32\") \n",
        "    valid_mask = mx.ndarray.ndarray.array(valid_mask, dtype=\"int32\") \n",
        "    test_mask = mx.ndarray.ndarray.array(test_mask, dtype=\"int32\")\n",
        "    #train_mask = mx.ndarray.ndarray.array(train_mask) \n",
        "    #valid_mask = mx.ndarray.ndarray.array(valid_mask) \n",
        "    #test_mask = mx.ndarray.ndarray.array(test_mask)\n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        with autograd.record():\n",
        "            y_hat = net(g, features)\n",
        "            loss = loss_func(y_hat[train_mask], labels[train_mask])\n",
        "            #print(loss.shape)\n",
        "\n",
        "        loss.backward()\n",
        "        trainer.step(1)\n",
        "\n",
        "        pred = y_hat.argmax(1)\n",
        "        pred = mx.nd.array(pred, dtype=\"int64\")\n",
        "        #print(pred[train_mask]-labels[train_mask])\n",
        "        #print(pred[valid_mask]-labels[valid_mask])\n",
        "        \n",
        "        #print(pred[valid_mask])\n",
        "        #print(labels[valid_mask])\n",
        "        #print(float(mx.nd.sum(pred[valid_mask]==labels[valid_mask]).asnumpy()))\n",
        "        #print(len(pred[valid_mask]))\n",
        "        train_acc = float(mx.nd.sum(pred[train_mask]==labels[train_mask]).asnumpy())/len(pred[train_mask])\n",
        "        valid_acc = float(mx.nd.sum(pred[valid_mask]==labels[valid_mask]).asnumpy())/len(pred[valid_mask])\n",
        "        test_acc = float(mx.nd.sum(pred[test_mask]==labels[test_mask]).asnumpy())/len(pred[test_mask])\n",
        "        print(f\"epoch {epoch}: {float(train_acc):f} / {float(valid_acc):f} / {float(test_acc):f} / {float(loss.mean().asnumpy()):f}\")\n",
        "\n",
        "train(g, net, 100, {\"learning_rate\" : 0.01})"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: 0.128571 / 0.150000 / 0.115000 / 1.945959\n",
            "epoch 2: 0.214286 / 0.114000 / 0.131000 / 1.942345\n",
            "epoch 3: 0.492857 / 0.318000 / 0.328000 / 1.937484\n",
            "epoch 4: 0.628571 / 0.442000 / 0.489000 / 1.930079\n",
            "epoch 5: 0.785714 / 0.508000 / 0.506000 / 1.921127\n",
            "epoch 6: 0.785714 / 0.502000 / 0.486000 / 1.912048\n",
            "epoch 7: 0.771429 / 0.508000 / 0.487000 / 1.902626\n",
            "epoch 8: 0.792857 / 0.522000 / 0.511000 / 1.891933\n",
            "epoch 9: 0.814286 / 0.528000 / 0.539000 / 1.879992\n",
            "epoch 10: 0.821429 / 0.536000 / 0.552000 / 1.867304\n",
            "epoch 11: 0.842857 / 0.560000 / 0.557000 / 1.853449\n",
            "epoch 12: 0.842857 / 0.574000 / 0.569000 / 1.838529\n",
            "epoch 13: 0.835714 / 0.578000 / 0.577000 / 1.822859\n",
            "epoch 14: 0.850000 / 0.578000 / 0.587000 / 1.806265\n",
            "epoch 15: 0.864286 / 0.596000 / 0.597000 / 1.788679\n",
            "epoch 16: 0.850000 / 0.610000 / 0.608000 / 1.770063\n",
            "epoch 17: 0.864286 / 0.618000 / 0.616000 / 1.750437\n",
            "epoch 18: 0.878571 / 0.626000 / 0.625000 / 1.729845\n",
            "epoch 19: 0.885714 / 0.628000 / 0.632000 / 1.708329\n",
            "epoch 20: 0.900000 / 0.630000 / 0.642000 / 1.685864\n",
            "epoch 21: 0.907143 / 0.624000 / 0.645000 / 1.662449\n",
            "epoch 22: 0.907143 / 0.628000 / 0.647000 / 1.638085\n",
            "epoch 23: 0.900000 / 0.632000 / 0.648000 / 1.612842\n",
            "epoch 24: 0.892857 / 0.636000 / 0.652000 / 1.586704\n",
            "epoch 25: 0.892857 / 0.638000 / 0.653000 / 1.559687\n",
            "epoch 26: 0.892857 / 0.644000 / 0.654000 / 1.531907\n",
            "epoch 27: 0.892857 / 0.646000 / 0.655000 / 1.503374\n",
            "epoch 28: 0.900000 / 0.644000 / 0.656000 / 1.474101\n",
            "epoch 29: 0.914286 / 0.644000 / 0.662000 / 1.444121\n",
            "epoch 30: 0.928571 / 0.644000 / 0.662000 / 1.413531\n",
            "epoch 31: 0.935714 / 0.652000 / 0.667000 / 1.382352\n",
            "epoch 32: 0.935714 / 0.654000 / 0.671000 / 1.350683\n",
            "epoch 33: 0.935714 / 0.658000 / 0.673000 / 1.318595\n",
            "epoch 34: 0.935714 / 0.658000 / 0.675000 / 1.286176\n",
            "epoch 35: 0.942857 / 0.662000 / 0.678000 / 1.253500\n",
            "epoch 36: 0.942857 / 0.666000 / 0.679000 / 1.220608\n",
            "epoch 37: 0.950000 / 0.674000 / 0.681000 / 1.187577\n",
            "epoch 38: 0.950000 / 0.678000 / 0.680000 / 1.154491\n",
            "epoch 39: 0.950000 / 0.680000 / 0.687000 / 1.121412\n",
            "epoch 40: 0.950000 / 0.684000 / 0.691000 / 1.088402\n",
            "epoch 41: 0.950000 / 0.686000 / 0.694000 / 1.055536\n",
            "epoch 42: 0.950000 / 0.688000 / 0.696000 / 1.022882\n",
            "epoch 43: 0.950000 / 0.692000 / 0.703000 / 0.990523\n",
            "epoch 44: 0.950000 / 0.700000 / 0.704000 / 0.958495\n",
            "epoch 45: 0.950000 / 0.702000 / 0.713000 / 0.926874\n",
            "epoch 46: 0.957143 / 0.704000 / 0.718000 / 0.895700\n",
            "epoch 47: 0.957143 / 0.706000 / 0.722000 / 0.865026\n",
            "epoch 48: 0.971429 / 0.710000 / 0.723000 / 0.834890\n",
            "epoch 49: 0.971429 / 0.714000 / 0.729000 / 0.805367\n",
            "epoch 50: 0.971429 / 0.716000 / 0.734000 / 0.776474\n",
            "epoch 51: 0.971429 / 0.718000 / 0.734000 / 0.748242\n",
            "epoch 52: 0.971429 / 0.720000 / 0.737000 / 0.720683\n",
            "epoch 53: 0.971429 / 0.722000 / 0.735000 / 0.693852\n",
            "epoch 54: 0.971429 / 0.724000 / 0.738000 / 0.667751\n",
            "epoch 55: 0.971429 / 0.724000 / 0.740000 / 0.642395\n",
            "epoch 56: 0.971429 / 0.724000 / 0.743000 / 0.617804\n",
            "epoch 57: 0.971429 / 0.726000 / 0.745000 / 0.593992\n",
            "epoch 58: 0.978571 / 0.726000 / 0.747000 / 0.570963\n",
            "epoch 59: 0.985714 / 0.728000 / 0.748000 / 0.548709\n",
            "epoch 60: 0.985714 / 0.730000 / 0.750000 / 0.527228\n",
            "epoch 61: 0.985714 / 0.736000 / 0.751000 / 0.506504\n",
            "epoch 62: 0.985714 / 0.740000 / 0.750000 / 0.486541\n",
            "epoch 63: 0.985714 / 0.740000 / 0.751000 / 0.467324\n",
            "epoch 64: 0.985714 / 0.748000 / 0.750000 / 0.448841\n",
            "epoch 65: 0.985714 / 0.750000 / 0.751000 / 0.431076\n",
            "epoch 66: 0.985714 / 0.748000 / 0.752000 / 0.414002\n",
            "epoch 67: 0.985714 / 0.750000 / 0.756000 / 0.397616\n",
            "epoch 68: 0.985714 / 0.752000 / 0.756000 / 0.381900\n",
            "epoch 69: 0.992857 / 0.754000 / 0.757000 / 0.366829\n",
            "epoch 70: 0.992857 / 0.754000 / 0.756000 / 0.352379\n",
            "epoch 71: 0.992857 / 0.756000 / 0.756000 / 0.338532\n",
            "epoch 72: 0.992857 / 0.754000 / 0.757000 / 0.325267\n",
            "epoch 73: 0.992857 / 0.756000 / 0.758000 / 0.312563\n",
            "epoch 74: 0.992857 / 0.756000 / 0.758000 / 0.300405\n",
            "epoch 75: 0.992857 / 0.756000 / 0.758000 / 0.288771\n",
            "epoch 76: 0.992857 / 0.756000 / 0.758000 / 0.277641\n",
            "epoch 77: 0.992857 / 0.754000 / 0.758000 / 0.266989\n",
            "epoch 78: 0.992857 / 0.754000 / 0.760000 / 0.256799\n",
            "epoch 79: 0.992857 / 0.754000 / 0.760000 / 0.247056\n",
            "epoch 80: 0.992857 / 0.754000 / 0.760000 / 0.237745\n",
            "epoch 81: 0.992857 / 0.756000 / 0.760000 / 0.228848\n",
            "epoch 82: 1.000000 / 0.756000 / 0.764000 / 0.220339\n",
            "epoch 83: 1.000000 / 0.756000 / 0.764000 / 0.212208\n",
            "epoch 84: 1.000000 / 0.756000 / 0.762000 / 0.204442\n",
            "epoch 85: 1.000000 / 0.758000 / 0.760000 / 0.197024\n",
            "epoch 86: 1.000000 / 0.756000 / 0.761000 / 0.189929\n",
            "epoch 87: 1.000000 / 0.756000 / 0.763000 / 0.183146\n",
            "epoch 88: 1.000000 / 0.756000 / 0.763000 / 0.176665\n",
            "epoch 89: 1.000000 / 0.760000 / 0.762000 / 0.170471\n",
            "epoch 90: 1.000000 / 0.764000 / 0.764000 / 0.164554\n",
            "epoch 91: 1.000000 / 0.762000 / 0.763000 / 0.158901\n",
            "epoch 92: 1.000000 / 0.762000 / 0.762000 / 0.153494\n",
            "epoch 93: 1.000000 / 0.762000 / 0.762000 / 0.148326\n",
            "epoch 94: 1.000000 / 0.764000 / 0.762000 / 0.143387\n",
            "epoch 95: 1.000000 / 0.764000 / 0.762000 / 0.138663\n",
            "epoch 96: 1.000000 / 0.764000 / 0.763000 / 0.134143\n",
            "epoch 97: 1.000000 / 0.764000 / 0.762000 / 0.129815\n",
            "epoch 98: 1.000000 / 0.764000 / 0.762000 / 0.125672\n",
            "epoch 99: 1.000000 / 0.766000 / 0.760000 / 0.121702\n",
            "epoch 100: 1.000000 / 0.766000 / 0.760000 / 0.117903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmokTeFSskDg",
        "outputId": "7f164c68-447b-4e72-cc03-af2f83bcdee7"
      },
      "source": [
        "labels = g.ndata['label']\n",
        "labels_one_hot = mx.nd.one_hot(labels, 7)\n",
        "mx.nd.argmax(mx.nd.abs(net(g, g.ndata['feat'])-labels_one_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1207.]\n",
              "<NDArray 1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ae6xeWcTrEI",
        "outputId": "ffaa50db-7c03-4ed7-b300-0088bda487e9"
      },
      "source": [
        "mx.nd.sum(mx.nd.abs(net(g, g.ndata['feat'])-labels_one_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1343.6486]\n",
              "<NDArray 1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CcnzzKpUJfG",
        "outputId": "8125bfde-3cf7-42a2-f380-b5965e92af35"
      },
      "source": [
        "len(labels_one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k9KqAIXTxTN",
        "outputId": "dd9235a9-7f85-460c-e895-f2e571832d7a"
      },
      "source": [
        "net(g, g.ndata['feat'])[1207]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[7.4344091e-05 1.1085745e-08 4.6792929e-06 1.0696469e-09 7.8606173e-02\n",
              " 2.8811020e-10 1.8635015e-05]\n",
              "<NDArray 7 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn-JnosOT0mo",
        "outputId": "97aa2db9-3ac6-4678-a15c-818d6a298fc7"
      },
      "source": [
        "labels_one_hot[1207]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[0. 0. 0. 0. 1. 0. 0.]\n",
              "<NDArray 7 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIZPLQJgBYBH",
        "outputId": "5fe7b3b2-7c32-4327-b3a5-248c4666d977"
      },
      "source": [
        "type(g.ndata['train_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mxnet.ndarray.ndarray.NDArray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ws0N69Usorx",
        "outputId": "86bd915a-31bc-4631-ac45-3855559b918d"
      },
      "source": [
        "g.ndata['train_mask'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2708,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4KHRNKotPre",
        "outputId": "5acdcedb-a9c6-40a3-89b8-49e37d0d8659"
      },
      "source": [
        "mx.nd.sum(g.ndata['train_mask'])[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[140.]\n",
              "<NDArray 1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIVmeR3KuGGM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}